{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07. Practical Project: Building a Character Lookup Table\n",
        "\n",
        "In this final notebook, we'll put everything together to build a complete character lookup table. This project demonstrates a real-world workflow for creating data structures useful for dictionaries and character composers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Goal\n",
        "\n",
        "Build a comprehensive character lookup table that includes:\n",
        "1. Character variants (simplified/traditional, shinjitai/kyujitai)\n",
        "2. Basic statistics about variant relationships\n",
        "3. Export in a format useful for dictionary/composer applications\n",
        "\n",
        "## Step 1: Load Multiple Data Sources\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load simplified/traditional Chinese variants\n",
        "df_simplified = pd.read_csv('../cjkvi-variants/cjkvi-simplified.txt',\n",
        "                            sep=',',\n",
        "                            comment='#',\n",
        "                            names=['variant', 'type', 'target'],\n",
        "                            encoding='utf-8')\n",
        "\n",
        "# Load Japanese joyo variants\n",
        "df_joyo = pd.read_csv('../cjkvi-variants/joyo-variants.txt',\n",
        "                     sep=',',\n",
        "                     comment='#',\n",
        "                     names=['character', 'type', 'variant'],\n",
        "                     encoding='utf-8')\n",
        "\n",
        "# Load shinjitai data\n",
        "with open('../shinjitai-table/shinjitai.json', 'r', encoding='utf-8') as f:\n",
        "    shinjitai_data = json.load(f)\n",
        "\n",
        "shinjitai_list = []\n",
        "for shinjitai, kyujitai_list in shinjitai_data.items():\n",
        "    if kyujitai_list:\n",
        "        for kyujitai in kyujitai_list:\n",
        "            shinjitai_list.append({'shinjitai': shinjitai, 'kyujitai': kyujitai})\n",
        "\n",
        "df_shinjitai = pd.DataFrame(shinjitai_list)\n",
        "\n",
        "print(\"Data loaded:\")\n",
        "print(f\"  Simplified variants: {len(df_simplified)} rows\")\n",
        "print(f\"  Joyo variants: {len(df_joyo)} rows\")\n",
        "print(f\"  Shinjitai mappings: {len(df_shinjitai)} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clean and Filter Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter for simplified Chinese only\n",
        "df_simp = df_simplified[df_simplified['type'] == 'cjkvi/simplified'][['variant', 'target']].copy()\n",
        "df_simp.columns = ['simplified', 'traditional']\n",
        "\n",
        "# Filter for traditional Chinese only\n",
        "df_trad = df_simplified[df_simplified['type'] == 'cjkvi/traditional'][['variant', 'target']].copy()\n",
        "df_trad.columns = ['traditional', 'simplified']\n",
        "\n",
        "print(\"Filtered data:\")\n",
        "print(f\"  Simplified → Traditional: {len(df_simp)} mappings\")\n",
        "print(f\"  Traditional → Simplified: {len(df_trad)} mappings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Merge Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a base character list from all sources\n",
        "all_chars = set()\n",
        "all_chars.update(df_simp['simplified'].unique())\n",
        "all_chars.update(df_simp['traditional'].unique())\n",
        "all_chars.update(df_joyo['character'].unique())\n",
        "all_chars.update(df_shinjitai['shinjitai'].unique())\n",
        "\n",
        "df_base = pd.DataFrame({'character': list(all_chars)})\n",
        "print(f\"Base character list: {len(df_base)} unique characters\")\n",
        "\n",
        "# Merge with simplified/traditional mappings\n",
        "df_merged = pd.merge(df_base, df_simp,\n",
        "                     left_on='character',\n",
        "                     right_on='simplified',\n",
        "                     how='left')\n",
        "\n",
        "# Also add reverse mapping (traditional → simplified)\n",
        "df_merged = pd.merge(df_merged, df_trad,\n",
        "                     left_on='character',\n",
        "                     right_on='traditional',\n",
        "                     how='left',\n",
        "                     suffixes=('', '_rev'))\n",
        "\n",
        "# Clean up columns\n",
        "if 'simplified_rev' in df_merged.columns:\n",
        "    df_merged['simplified'] = df_merged['simplified'].fillna(df_merged['simplified_rev'])\n",
        "    df_merged = df_merged.drop(columns=['simplified_rev', 'traditional_rev'])\n",
        "\n",
        "print(f\"\\nAfter merging variant data: {len(df_merged)} rows\")\n",
        "df_merged.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Add Japanese Variant Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge with shinjitai data\n",
        "df_final = pd.merge(df_merged, df_shinjitai,\n",
        "                   left_on='character',\n",
        "                   right_on='shinjitai',\n",
        "                   how='left')\n",
        "\n",
        "# Add joyo variant information\n",
        "df_joyo_variants = df_joyo.groupby('character')['variant'].apply(list).reset_index()\n",
        "df_joyo_variants.columns = ['character', 'joyo_variants']\n",
        "\n",
        "df_final = pd.merge(df_final, df_joyo_variants,\n",
        "                   on='character',\n",
        "                   how='left')\n",
        "\n",
        "print(f\"Final merged table: {len(df_final)} rows\")\n",
        "df_final.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Analyze with Basic Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count characters with different types of variant information\n",
        "print(\"Variant type distribution:\")\n",
        "print(f\"  Characters with simplified/traditional mapping: {df_final['simplified'].notna().sum()}\")\n",
        "print(f\"  Characters with shinjitai/kyujitai mapping: {df_final['kyujitai'].notna().sum()}\")\n",
        "print(f\"  Characters with joyo variants: {df_final['joyo_variants'].notna().sum()}\")\n",
        "\n",
        "# Count characters with multiple variant types\n",
        "has_multiple = (df_final['simplified'].notna().astype(int) + \n",
        "                df_final['kyujitai'].notna().astype(int) + \n",
        "                df_final['joyo_variants'].notna().astype(int)) >= 2\n",
        "\n",
        "print(f\"\\nCharacters with 2+ variant types: {has_multiple.sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Lookup Tables and Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a character → all variants lookup dictionary\n",
        "lookup_dict = {}\n",
        "for idx, row in df_final.iterrows():\n",
        "    char = row['character']\n",
        "    variants = []\n",
        "    \n",
        "    if pd.notna(row['traditional']):\n",
        "        variants.append(('traditional', row['traditional']))\n",
        "    if pd.notna(row['simplified']):\n",
        "        variants.append(('simplified', row['simplified']))\n",
        "    if pd.notna(row['kyujitai']):\n",
        "        variants.append(('kyujitai', row['kyujitai']))\n",
        "    if pd.notna(row['joyo_variants']):\n",
        "        for var in row['joyo_variants']:\n",
        "            variants.append(('joyo', var))\n",
        "    \n",
        "    if variants:\n",
        "        lookup_dict[char] = variants\n",
        "\n",
        "print(f\"Created lookup dictionary with {len(lookup_dict)} characters\")\n",
        "print(\"\\nExample entries:\")\n",
        "for char, variants in list(lookup_dict.items())[:3]:\n",
        "    print(f\"  {char}: {variants}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to JSON\n",
        "output_file = 'character_lookup.json'\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(lookup_dict, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Exported lookup table to {output_file}\")\n",
        "\n",
        "# Also export the full DataFrame to CSV\n",
        "df_final.to_csv('character_table.csv', index=False, encoding='utf-8')\n",
        "print(\"Exported full table to character_table.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Summary\n",
        "\n",
        "We've successfully:\n",
        "1. ✅ Loaded data from multiple sources (CSV, JSON)\n",
        "2. ✅ Cleaned and filtered the data\n",
        "3. ✅ Merged datasets using different join types\n",
        "4. ✅ Added computed columns and transformations\n",
        "5. ✅ Performed basic statistical analysis\n",
        "6. ✅ Created lookup tables\n",
        "7. ✅ Exported results for use in applications\n",
        "\n",
        "## What You've Learned\n",
        "\n",
        "Throughout this series, you've learned:\n",
        "- How to load data from various file formats\n",
        "- How to explore and inspect DataFrames\n",
        "- How to filter data based on conditions\n",
        "- **How to merge datasets** (most critical skill!)\n",
        "- How to transform data and create lookup tables\n",
        "- How to perform basic statistics and grouping\n",
        "- How to build complete data processing workflows\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "You're now ready to:\n",
        "- Work with AI assistance for more complex data analysis (Part 3)\n",
        "- Build your own character lookup tools\n",
        "- Process CHISE and other CJK character databases\n",
        "- Create data structures for character composers and dictionaries\n",
        "\n",
        "## Reference Materials\n",
        "\n",
        "For deeper learning, continue with:\n",
        "- **PANDAS-TUTORIAL** in `../PANDAS-TUTORIAL/` for advanced topics\n",
        "- [Pandas Official Documentation](https://pandas.pydata.org/docs/)\n",
        "\n",
        "## Try It Yourself\n",
        "\n",
        "1. Extend this project by adding IDS data\n",
        "2. Create a component → characters forward map\n",
        "3. Build variant → standard reverse lookup tables\n",
        "4. Experiment with different merge strategies\n",
        "5. Add more data sources and see how they combine\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
