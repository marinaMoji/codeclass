{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04. Merging Datasets\n",
        "\n",
        "Merging is one of the most powerful skills in data analysis. You'll use it constantly to combine information from different sources, like adding stroke counts to your IDS table, or finding which characters appear in multiple variant lists.\n",
        "\n",
        "You can do glorious things merging data. First, however, you will be merging things that don't work until 4 A.M.\n",
        "\n",
        "Let's load the IDS table and the clean stroke count table that Marina so kindly cleaned for us in the last notebook:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the IDS table\n",
        "ids_df = pd.read_csv('../daniel_tables/ids_df.csv',\n",
        "    index_col=None,\n",
        "    encoding='utf-8')\n",
        "\n",
        "# Load the clean stroke count table\n",
        "stroke_df = pd.read_csv('../marina_tables/stroke_count_clean.csv',\n",
        "    index_col=None,\n",
        "    encoding='utf-8')\n",
        "\n",
        "# Print the head of both tables\n",
        "print(\"IDS Table:\")\n",
        "print(ids_df.head())\n",
        "print(f\"\\nIDS Table shape: {ids_df.shape}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(\"Stroke Count Table:\")\n",
        "print(stroke_df.head())\n",
        "print(f\"\\nStroke Count Table shape: {stroke_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OK, so we have two tables. The IDS table has character decomposition information, and the stroke count table has... well, stroke counts. Wouldn't it be nice if we could combine them? Like, have one table with both the components AND the stroke count for each character?\n",
        "\n",
        "That's what merging is for! But here's the thing: not every character in the IDS table has a stroke count, and not every character in the stroke count table has IDS decomposition data. So we need to decide: what do we want to keep?\n",
        "\n",
        "Pandas gives us several options, and they're called \"joins\". Let's see what happens with each one:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inner Join: Only Matching Characters\n",
        "\n",
        "An inner join keeps ONLY the rows where the character exists in BOTH tables. This is the most restrictive option - if a character doesn't have a stroke count, it gets dropped. If a character doesn't have IDS data, it gets dropped.\n",
        "\n",
        "Use this when you only want complete data - characters that have information in both tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simplified → Traditional mappings:\n",
            "Rows: 8399\n",
            "\n",
            "Traditional → Simplified mappings:\n",
            "Rows: 5097\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>traditional</th>\n",
              "      <th>simplified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8588</th>\n",
              "      <td>㐷</td>\n",
              "      <td>傌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8589</th>\n",
              "      <td>㐹</td>\n",
              "      <td>㑶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8590</th>\n",
              "      <td>㐽</td>\n",
              "      <td>偑</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8591</th>\n",
              "      <td>㑇</td>\n",
              "      <td>㑳</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8592</th>\n",
              "      <td>㑈</td>\n",
              "      <td>倲</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     traditional simplified\n",
              "8588           㐷          傌\n",
              "8589           㐹          㑶\n",
              "8590           㐽          偑\n",
              "8591           㑇          㑳\n",
              "8592           㑈          倲"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inner join: only keep characters that exist in BOTH tables\n",
        "df_inner = pd.merge(ids_df, stroke_df,\n",
        "                    on='character',\n",
        "                    how='inner')\n",
        "\n",
        "print(f\"Original IDS table: {len(ids_df)} rows\")\n",
        "print(f\"Original stroke count table: {len(stroke_df)} rows\")\n",
        "print(f\"After inner join: {len(df_inner)} rows\")\n",
        "print(f\"\\nLost {len(ids_df) - len(df_inner)} rows from IDS table\")\n",
        "print(f\"Lost {len(stroke_df) - len(df_inner)} rows from stroke count table\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_inner.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Left Join: Keep All IDS Characters\n",
        "\n",
        "A left join keeps ALL rows from the LEFT table (ids_df) and adds matching data from the RIGHT table (stroke_df) where it exists. If there's no match, the stroke count columns will be empty (NaN).\n",
        "\n",
        "Use this when you want to keep all your IDS data, even if some characters don't have stroke counts yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Left join: keep all IDS characters, add stroke counts where available\n",
        "df_left = pd.merge(ids_df, stroke_df,\n",
        "                   on='character',\n",
        "                   how='left')\n",
        "\n",
        "print(f\"Original IDS table: {len(ids_df)} rows\")\n",
        "print(f\"After left join: {len(df_left)} rows\")\n",
        "print(f\"\\nKept all {len(ids_df)} rows from IDS table!\")\n",
        "print(f\"Added stroke counts for {df_left['stroke_count'].notna().sum()} characters\")\n",
        "print(f\"Missing stroke counts for {df_left['stroke_count'].isna().sum()} characters\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_left.head())\n",
        "print(\"\\nSome rows with missing stroke counts:\")\n",
        "print(df_left[df_left['stroke_count'].isna()].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Right Join: Keep All Stroke Count Characters\n",
        "\n",
        "A right join keeps ALL rows from the RIGHT table (stroke_df) and adds matching data from the LEFT table (ids_df) where it exists. If there's no match, the IDS columns will be empty (NaN).\n",
        "\n",
        "Use this when you want to keep all your stroke count data, even if some characters don't have IDS decomposition yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Right join: keep all stroke count characters, add IDS data where available\n",
        "df_right = pd.merge(ids_df, stroke_df,\n",
        "                    on='character',\n",
        "                    how='right')\n",
        "\n",
        "print(f\"Original stroke count table: {len(stroke_df)} rows\")\n",
        "print(f\"After right join: {len(df_right)} rows\")\n",
        "print(f\"\\nKept all {len(stroke_df)} rows from stroke count table!\")\n",
        "print(f\"Added IDS data for {df_right['components'].notna().sum()} characters\")\n",
        "print(f\"Missing IDS data for {df_right['components'].isna().sum()} characters\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_right.head())\n",
        "print(\"\\nSome rows with missing IDS data:\")\n",
        "print(df_right[df_right['components'].isna()].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing the Results\n",
        "\n",
        "OK Marina, let's see what we learned. Why are the sizes different?\n",
        "\n",
        "The key is understanding what each join type keeps:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare the sizes\n",
        "print(\"Summary of merge results:\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Original IDS table:           {len(ids_df):,} rows\")\n",
        "print(f\"Original stroke count table:   {len(stroke_df):,} rows\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Inner join:  {len(df_inner):,} rows (only characters in BOTH tables)\")\n",
        "print(f\"Left join:   {len(df_left):,} rows (all IDS + matching stroke counts)\")\n",
        "print(f\"Right join:  {len(df_right):,} rows (all stroke counts + matching IDS)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nWhy is inner join smaller?\")\n",
        "print(f\"  → Because {len(ids_df) - len(df_inner):,} characters in IDS table don't have stroke counts\")\n",
        "print(f\"  → And {len(stroke_df) - len(df_inner):,} characters in stroke count table don't have IDS data\")\n",
        "print(f\"\\nWhy are left and right joins different sizes?\")\n",
        "print(f\"  → Left join keeps all {len(ids_df):,} IDS characters (some without stroke counts)\")\n",
        "print(f\"  → Right join keeps all {len(stroke_df):,} stroke count characters (some without IDS data)\")\n",
        "print(f\"  → They're different because the two tables have different characters!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perfect! Now you understand the difference. For most of your work, you'll probably want to use **left join** to keep all your IDS data and add stroke counts where available.\n",
        "\n",
        "But wait, there's more! Merging isn't just for combining different tables - you can also merge a table **onto itself**. This is super useful for finding relationships within the same data.\n",
        "\n",
        "Let's do something cool: we're going to extract all the **radical components** from each character's decomposition. Not just the direct components, but the components of those components, and the components of THOSE components. We'll go 2-3 levels deep, and then you can go deeper on your own time if you want.\n",
        "\n",
        "First, let's define what we mean by \"radicals\":\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard radicals list (from Jisho.org)\n",
        "radicals = [\n",
        "    '一', '｜', '丶', 'ノ', '乙', '亅', '二', '亠', '人', '⺅', '𠆢', '儿', '入', 'ハ', '丷', '冂', \n",
        "    '冖', '冫', '几', '凵', '刀', '⺉', '力', '勹', '匕', '匚', '十', '卜', '卩', '厂', '厶', '又', \n",
        "    'マ', '九', 'ユ', '乃', '𠂉', '⻌', '口', '囗', '土', '士', '夂', '夕', '大', '女', '子', '宀', \n",
        "    '寸', '小', '⺌', '尢', '尸', '屮', '山', '川', '巛', '工', '已', '巾', '干', '幺', '广', '廴', \n",
        "    '廾', '弋', '弓', 'ヨ', '彑', '彡', '彳', '⺖', '⺘', '⺡', '⺨', '⺾', '⻏⻖', '也', '亡', '及', \n",
        "    '久', '⺹', '心', '戈', '戸', '手', '支', '攵', '文', '斗', '斤', '方', '无', '日', '曰', '月', \n",
        "    '木', '欠', '止', '歹', '殳', '比', '毛', '氏', '气', '水', '火', '⺣', '爪', '父', '爻', '爿', \n",
        "    '片', '牛', '犬', '⺭', '王', '元', '井', '勿', '尤', '五', '屯', '巴', '毋', '玄', '瓦', '甘', \n",
        "    '生', '用', '田', '疋', '疒', '癶', '白', '皮', '皿', '目', '矛', '矢', '石', '示', '禸', '禾', \n",
        "    '穴', '立', '⻂', '世', '巨', '冊', '母', '⺲', '牙', '瓜', '竹', '米', '糸', '缶', '羊', '羽', \n",
        "    '而', '耒', '耳', '聿', '肉', '自', '至', '臼', '舌', '舟', '艮', '色', '虍', '虫', '血', '行', \n",
        "    '衣', '西', '臣', '見', '角', '言', '谷', '豆', '豕', '豸', '貝', '赤', '走', '足', '身', '車', \n",
        "    '辛', '辰', '酉', '釆', '里', '舛', '麦', '金', '長', '門', '隶', '隹', '雨', '青', '非', '奄', \n",
        "    '岡', '免', '斉', '面', '革', '韭', '音', '頁', '風', '飛', '食', '首', '香', '品', '馬', '骨', \n",
        "    '高', '髟', '鬥', '鬯', '鬲', '鬼', '竜', '韋', '魚', '鳥', '鹵', '鹿', '麻', '亀', '啇', '黄', \n",
        "    '黒', '黍', '黹', '無', '歯', '黽', '鼎', '鼓', '鼠', '鼻', '齊', '龠'\n",
        "]\n",
        "\n",
        "print(f\"Total radicals: {len(radicals)}\")\n",
        "print(f\"First 20: {radicals[:20]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Level 1: Extract Direct Radical Components\n",
        "\n",
        "First, we need to extract individual characters from the `components` column. The components column contains IDS notation with structure characters like ⿰⿱⿲⿳⿴⿵⿶⿷⿸⿹⿺⿻ that tell us how components are arranged. We want to extract just the actual CJK characters and filter for radicals.\n",
        "\n",
        "Here's a function to extract characters from an IDS string:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extract CJK characters from IDS notation\n",
        "def extract_characters(ids_string):\n",
        "    \"\"\"Extract individual CJK characters from an IDS string\"\"\"\n",
        "    if pd.isna(ids_string):\n",
        "        return []\n",
        "    \n",
        "    # IDS structure characters that we want to remove\n",
        "    structure_chars = '⿰⿱⿲⿳⿴⿵⿶⿷⿸⿹⿺⿻'\n",
        "    \n",
        "    # Extract only CJK characters (Unicode range roughly 0x4E00-0x9FFF for CJK Unified Ideographs)\n",
        "    # Also include some extended ranges for radicals and variants\n",
        "    chars = []\n",
        "    for char in str(ids_string):\n",
        "        # Skip structure characters and arrows (→, ←)\n",
        "        if char in structure_chars or char in '→←':\n",
        "            continue\n",
        "        # Check if it's a CJK character (rough check)\n",
        "        code = ord(char)\n",
        "        if (0x4E00 <= code <= 0x9FFF) or (0x3400 <= code <= 0x4DBF) or (0x20000 <= code <= 0x2A6DF):\n",
        "            chars.append(char)\n",
        "    \n",
        "    return chars\n",
        "\n",
        "# Test the function\n",
        "test_string = \"⿰歲刂\"\n",
        "print(f\"Test: {test_string} → {extract_characters(test_string)}\")\n",
        "\n",
        "# Apply to the components column\n",
        "ids_df['components_list'] = ids_df['components'].apply(extract_characters)\n",
        "\n",
        "# Extract only radicals from Level 1 (direct components)\n",
        "ids_df['radicals_level1'] = ids_df['components_list'].apply(\n",
        "    lambda chars: [c for c in chars if c in radicals]\n",
        ")\n",
        "\n",
        "print(\"\\nFirst few rows with extracted radicals:\")\n",
        "print(ids_df[['character', 'components', 'radicals_level1']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Good! Now we have Level 1 radicals - the radicals that appear directly in each character's components. But what about characters that are made up of other characters, which are in turn made up of radicals? We need to go deeper!\n",
        "\n",
        "## Level 2: Components of Components\n",
        "\n",
        "Now we're going to merge the table onto itself. For each character in the components list that isn't a radical, we'll look up its components and extract radicals from those.\n",
        "\n",
        "This is where self-joining gets interesting:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Create a lookup table of character -> components\n",
        "# We'll use this to look up components of components\n",
        "component_lookup = ids_df[['character', 'components_list']].copy()\n",
        "\n",
        "# Step 2: For each row, get all non-radical components\n",
        "# Then look up their components\n",
        "def get_level2_radicals(row):\n",
        "    \"\"\"Get radicals from Level 2 (components of components)\"\"\"\n",
        "    level2_radicals = []\n",
        "    \n",
        "    # Get all components from Level 1 that aren't radicals\n",
        "    non_radical_components = [c for c in row['components_list'] if c not in radicals]\n",
        "    \n",
        "    # For each non-radical component, look up its components\n",
        "    for comp in non_radical_components:\n",
        "        # Find this component in our lookup table\n",
        "        comp_data = component_lookup[component_lookup['character'] == comp]\n",
        "        if not comp_data.empty:\n",
        "            comp_components = comp_data.iloc[0]['components_list']\n",
        "            # Extract radicals from these components\n",
        "            comp_radicals = [c for c in comp_components if c in radicals]\n",
        "            level2_radicals.extend(comp_radicals)\n",
        "    \n",
        "    return level2_radicals\n",
        "\n",
        "# Apply the function\n",
        "ids_df['radicals_level2'] = ids_df.apply(get_level2_radicals, axis=1)\n",
        "\n",
        "print(\"First few rows with Level 2 radicals:\")\n",
        "print(ids_df[['character', 'components', 'radicals_level1', 'radicals_level2']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Excellent! Now we're getting radicals from components of components. But wait, there's more! What if those components-of-components also have components? Let's go one level deeper:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Level 3: Components of components of components\n",
        "def get_level3_radicals(row):\n",
        "    \"\"\"Get radicals from Level 3 (components of components of components)\"\"\"\n",
        "    level3_radicals = []\n",
        "    \n",
        "    # Get all non-radical components from Level 1\n",
        "    non_radical_components = [c for c in row['components_list'] if c not in radicals]\n",
        "    \n",
        "    # For each non-radical component, get its components\n",
        "    for comp in non_radical_components:\n",
        "        comp_data = component_lookup[component_lookup['character'] == comp]\n",
        "        if not comp_data.empty:\n",
        "            comp_components = comp_data.iloc[0]['components_list']\n",
        "            \n",
        "            # Now get components of these components (Level 3)\n",
        "            for comp2 in comp_components:\n",
        "                if comp2 not in radicals:  # Only look up if it's not already a radical\n",
        "                    comp2_data = component_lookup[component_lookup['character'] == comp2]\n",
        "                    if not comp2_data.empty:\n",
        "                        comp2_components = comp2_data.iloc[0]['components_list']\n",
        "                        # Extract radicals from Level 3\n",
        "                        comp2_radicals = [c for c in comp2_components if c in radicals]\n",
        "                        level3_radicals.extend(comp2_radicals)\n",
        "    \n",
        "    return level3_radicals\n",
        "\n",
        "# Apply the function\n",
        "ids_df['radicals_level3'] = ids_df.apply(get_level3_radicals, axis=1)\n",
        "\n",
        "print(\"First few rows with all three levels:\")\n",
        "print(ids_df[['character', 'components', 'radicals_level1', 'radicals_level2', 'radicals_level3']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perfect! Now we have radicals from three levels. The final step is to combine them all into a single column with unique radicals (no duplicates):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all levels into a single list of unique radicals\n",
        "def combine_all_radicals(row):\n",
        "    \"\"\"Combine radicals from all levels, removing duplicates\"\"\"\n",
        "    all_radicals = []\n",
        "    all_radicals.extend(row['radicals_level1'])\n",
        "    all_radicals.extend(row['radicals_level2'])\n",
        "    all_radicals.extend(row['radicals_level3'])\n",
        "    \n",
        "    # Remove duplicates while preserving order\n",
        "    seen = set()\n",
        "    unique_radicals = []\n",
        "    for rad in all_radicals:\n",
        "        if rad not in seen:\n",
        "            seen.add(rad)\n",
        "            unique_radicals.append(rad)\n",
        "    \n",
        "    return unique_radicals\n",
        "\n",
        "ids_df['radical_components'] = ids_df.apply(combine_all_radicals, axis=1)\n",
        "\n",
        "print(\"Final result with combined radical_components column:\")\n",
        "print(ids_df[['character', 'components', 'radical_components']].head(10))\n",
        "\n",
        "print(\"\\nSome examples with multiple radicals:\")\n",
        "examples = ids_df[ids_df['radical_components'].apply(len) > 2].head(5)\n",
        "for idx, row in examples.iterrows():\n",
        "    print(f\"\\n{row['character']}: {row['components']}\")\n",
        "    print(f\"  Radicals: {row['radical_components']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome! Now you have a column that lists all the radical components for each character, going 2-3 levels deep. \n",
        "\n",
        "## What We Learned\n",
        "\n",
        "1. **Inner Join**: Only keeps rows where the key exists in BOTH tables\n",
        "2. **Left Join**: Keeps all rows from the LEFT table, adds matching data from RIGHT\n",
        "3. **Right Join**: Keeps all rows from the RIGHT table, adds matching data from LEFT\n",
        "4. **Self-Join**: Merge a table onto itself to find relationships within the same data\n",
        "\n",
        "## Summary\n",
        "\n",
        "| Merge Type | `how=` | Keeps Rows From | Use When |\n",
        "|------------|--------|------------------|----------|\n",
        "| Inner | `'inner'` | Both DataFrames | You only want matching records |\n",
        "| Left | `'left'` | Left DataFrame | Keep all from left, add matching from right |\n",
        "| Right | `'right'` | Right DataFrame | Keep all from right, add matching from left |\n",
        "\n",
        "## Key Parameters\n",
        "\n",
        "- `on='column'` - Merge on a column with the same name in both DataFrames\n",
        "- `left_on='col1', right_on='col2'` - Merge on columns with different names\n",
        "- `how='inner'` - Type of join (inner, left, right, outer)\n",
        "\n",
        "## Try It Yourself\n",
        "\n",
        "1. Experiment with going deeper (Level 4, Level 5) to see how many radicals you can extract\n",
        "2. Try merging the stroke count data with the final radical_components column\n",
        "3. Count how many characters have each radical\n",
        "4. Find characters that share the same set of radicals\n",
        "\n",
        "## What's Next?\n",
        "\n",
        "In the next notebook, we'll learn how to:\n",
        "- Transform and manipulate data\n",
        "- Create new columns\n",
        "- Build lookup tables for dictionaries and character composers\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vanilla",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
